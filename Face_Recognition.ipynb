{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOGb0o9xWB7wVGX7b3LUJs3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zoya-Fathima/Resolute_AI_software_internship/blob/main/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxBfYw58ebH9"
      },
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import time\n",
        "KNOW_FACES_DIR='Known_faces'\n",
        "TOLERANCE=0.6\n",
        "FRAME_THICKNESS=3\n",
        "FONT_THICKNESS=2\n",
        "MODEL=\"cnn\"\n",
        "video=cv2.VideoCapture(0)\n",
        "print(\"Loading known faces\")\n",
        "known_faces=[]\n",
        "known_names=[]\n",
        "for name in os.listdir(\"C:\\\\Users\\\\mdzai\\\\OneDrive\\\\Desktop\\\\KNOWN_FACES\"):\n",
        "    for filename in os.listdir(\"C:\\\\Users\\\\mdzai\\\\OneDrive\\\\Desktop\\\\KNOWN_FACES\\\\\"+str(name)):\n",
        "        encoding=pickle.load(open(f\"{name}\\\\{filename}\",\"rb\"))\n",
        "        known_faces.append(encoding)\n",
        "        known_names.append(int(name))\n",
        "if len(known_names)>0:\n",
        "    next_id=max(known_names)\n",
        "else:\n",
        "    next_id=0\n",
        "print(\"Processing unknown faces\")\n",
        "while True:\n",
        "    ret,image=video.read()\n",
        "    locations=face_recognition.face_locations(image,model=MODEL)\n",
        "    encoding=face_recognition.face_encoding(image,locations)\n",
        "    for face_encoding, face_location in zip(encoding,locations):\n",
        "        results=face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
        "        match=None\n",
        "        if True in results:\n",
        "            match=known_names[results.index(True)]\n",
        "            print(f\"Match found: {match}\")\n",
        "        else:\n",
        "            match=str(next_id)\n",
        "            next_id+=1\n",
        "            known_names.append(match)\n",
        "            known_faces.append(face_encoding)\n",
        "            os.mkdir(f\"{KNOWN_FACES_DIR}/{match}\")\n",
        "            pickle.dump(face_encoding,open(f\"{KNOWN_FACES_DIR}/{match}/{match}-{int(time.time())}.pkl\",\"wb\"))\n",
        "        top_left=(face_location[3].face_location[0])\n",
        "        bottom_right=(face_location[1],face_location[2])\n",
        "        color=[0,255,0]\n",
        "        cv2.rectangle(image,top_left,bottom_right,color,FRAME_THICKNESS)\n",
        "        top_left=(face_location[3].face_location[2])\n",
        "        bottom_right=(face_location[1],face_location[2]+22)\n",
        "        cv2.rectangle(image,top_left,bottom_right,color,cv2.FILLED)\n",
        "        cv2.putText(image,match,(face_location[3]+10,face_location[2]+15), cv2.FONT_HERSHEY_SIMPLEX,0.5,(200,200,200))\n",
        "    cv2.imshow(\" \",image)\n",
        "    if cv2.waitKey(1)&0xFF==ord(\"q\"):\n",
        "        break\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}